# Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [1.5.0] - 2026-01-23

### Added

**GPT Codex Model Support (via copilot-api PR #170)**
- ğŸš€ Added support for all GPT Codex models via fork of copilot-api
  - `gpt-5.2-codex` (latest, recommended)
  - `gpt-5.1-codex`
  - `gpt-5.1-codex-mini`
  - `gpt-5.1-codex-max`
  - `gpt-5-codex`
- âœ¨ New launcher script `scripts/launch-responses-fork.sh`:
  - Auto-detects if PR #170 is merged (uses official npm if so)
  - Clones and builds fork automatically if needed
  - Health check before launching Claude Code
- âœ¨ New aliases: `ccfork`, `ccc-codex`, `ccc-codex-std`, `ccc-codex-mini`, `ccc-codex-max`
- ğŸ“ New documentation:
  - `docs/ALL-MODEL-COMMANDS.md` - Complete model reference (42 models)
  - `docs/ALL-MODEL-ALIASES.sh` - Ready-to-use alias file
  - `docs/QUICK-LAUNCH-GUIDE.md` - Fast setup guide
  - `docs/research/RESPONSES-API-TEST-RESULTS.md` - Fork test results (6/6 passed)

**Why Fork Required?**
- Codex models use OpenAI's `/responses` endpoint (launched Oct 2025)
- Official copilot-api v0.7.0 only supports `/chat/completions`
- PR #170 adds `/responses` endpoint support
- **Tracking**: [ericc-ch/copilot-api#170](https://github.com/ericc-ch/copilot-api/pull/170)

**Research Documentation**
- ğŸ“Š Added AgentAPI vs copilot-api comparative analysis in `docs/research/AGENTAPI-VS-COPILOT-API.md`:
  - Architectural differences: Terminal emulator vs API translation layer
  - Complementary tools verdict (not alternatives)
  - Use case decision matrix
  - Community metrics (Jan 2026)
  - Recommendation: Keep copilot-api for cc-copilot-bridge use case

**Security Documentation (Ollama)**
- ğŸ” Added Ollama security vulnerabilities section in `docs/SECURITY.md`:
  - CNVD-2025-04094: No authentication by default (Critical)
  - Model File OOB Write: RCE potential via malformed .gguf (High)
  - Model Poisoning: Unrestricted upload API (High)
- ğŸ” Added recommended hardening steps (firewall, resource limits)
- ğŸ” Source: Cisco Shodan Case Study on Ollama (2025)

**Air-Gapped Model Verification Protocol**
- ğŸ”’ Added 3-stage verification protocol in `docs/SECURITY.md`:
  - Stage 1: Download with SHA-256 checksums
  - Stage 2: Transfer with archive verification
  - Stage 3: Import with individual checksum verification
- ğŸ”’ Added audit trail requirements for regulated environments
- ğŸ”’ Reference: GitHub Issue #9756 (Ollama cannot verify integrity in air-gapped)

**KV Cache Quantization Documentation**
- âœ¨ Documented `OLLAMA_KV_CACHE_TYPE=q4_0` (Ollama 2025 feature)
- âœ¨ Reduces KV cache memory by ~75% (48GB â†’ 12GB for 64K context)
- âœ¨ Enables 64K context on 32GB machines

### Changed

**Memory Requirements Updated**
- ğŸ”§ Corrected RAM specs in `CLAUDE.md`:
  - Devstral 24B: 30-37GB total (was 23-27GB)
  - Granite4 32B: 34-41GB total
  - **Minimum**: 32GB for 24B, **48GB recommended** for 32B + 64K
- ğŸ”§ Updated `docs/OPTIMISATION-M4-PRO.md` with q4_0 cache type

**Model Recommendations**
- âš ï¸ Added warning for non-agentic models in `CLAUDE.md`:
  - CodeLlama:13b (~40% SWE-bench) - No tool calling
  - Llama3.1:8b (**15%** SWE-bench) - "Catastrophic failure" on agentic tasks
- âš ï¸ Note: High HumanEval â‰  agentic capability (Llama3.1:8b = 68% HumanEval but 15% SWE-bench)

### Security

- ğŸ” Added `.gitleaks.toml` configuration for secret detection
- ğŸ” Added GitHub Actions workflow `.github/workflows/security-scan.yml` for automated security scanning
- ğŸ” Gitleaks scans on every push/PR to detect accidentally committed credentials

### Changed

**Security Hardening**
- ğŸ”§ Replaced `sk-dummy` placeholder with `<PLACEHOLDER>` in `claude-switch` script
- ğŸ”§ Replaced token-like examples (`sk-...`) with `<YOUR_API_KEY>` in documentation
- ğŸ”§ Sanitized all credential placeholders across docs (CLAUDE.md, ARCHITECTURE.md, FEATURES.md, BEST-PRACTICES.md, TROUBLESHOOTING.md)
- ğŸ”§ Added explanatory comments for placeholder values (e.g., "copilot-api ignores this value")

**Documentation Cleanup**
- ğŸ“ CHEATSHEET.md: Complete rewrite (250 â†’ 39 lines) - now a true printable quick reference
  - Removed emojis (ASCII-only for terminal/printer compatibility)
  - Removed duplicate content from README/COMMANDS/TROUBLESHOOTING
  - Updated version v1.2.0 â†’ v1.4.0
  - Max line width: 65 columns (fits 80-column terminals)
- ğŸ“ QUICKSTART.md: Removed duplicate cheat sheet table, replaced with link
- ğŸ“ COMMANDS.md: Updated version header v1.2.0 â†’ v1.4.0

---

## [1.4.0] - 2026-01-22

### Changed

**Ollama Provider Overhaul**
- ğŸ”§ **Default model changed**: `qwen2.5-coder:32b-instruct` â†’ `devstral-small-2` (68% SWE-bench, better agentic coding)
- ğŸ”§ **Backup model added**: `ibm/granite4:small-h` (70% less VRAM with hybrid Mamba architecture)
- ğŸ”§ **Context warning**: Script now warns if Ollama context < 32K (Claude Code needs ~18K for system prompt + tools)

**New Aliases**
- `cco-devstral` â†’ Devstral-small-2 (default, best agentic)
- `cco-granite` â†’ Granite4 (long context, RAM-efficient)

### Added

**Ollama Context Configuration**
- âœ¨ New `_check_ollama_context()` function warns when context is too low
- ğŸ“ Instructions for creating 64K Modelfile (persistent context configuration)
- ğŸ“ Verification command: `ollama ps` shows effective context

**Documentation Updates**
- ğŸ“ CLAUDE.md: Updated Ollama section with new models, context setup, memory footprint
- ğŸ“ TROUBLESHOOTING.md: Complete rewrite of Ollama slow/hallucination section with 64K Modelfile solution
- ğŸ“ MODEL-SWITCHING.md: New "ModÃ¨les Ollama" section with Devstral, Granite4, and context configuration
- ğŸ“ README.md: Updated Ollama section with context warning and new recommended models

### Technical Details

**Why Devstral over Qwen2.5?**
- Devstral uses Mistral/OpenAI-style tool-calling format â†’ more compatible with Claude Code
- Qwen2.5 emits tools in `content` instead of structured `tool_calls` â†’ parsing issues
- Confirmed bug: "stuck on Explore" behavior with Qwen2.5 ([GitHub issue](https://github.com/QwenLM/Qwen3-Coder/issues/180))

**Context Configuration**
- Claude Code sends ~18K tokens of system prompt + tools
- Default Ollama context (4K) causes: hallucinations, "stuck on Explore", 2-6 min responses
- Recommended: 64K Modelfile (persistent) > environment variable (global fallback)
- Verification: `ollama ps` shows CONTEXT column (not `ollama show`)

**Memory Footprint (M4 Pro 48GB with 64K context)**
- Devstral Q4_K_M: 15GB model + 8-12GB cache = ~27GB total â†’ ~21GB free
- Granite4 hybrid: ~10GB active â†’ more headroom for context

### Sources

- [Taletskiy blog](https://taletskiy.com/blogs/ollama-claude-code/) - Original Ollama + Claude Code research
- [docs.ollama - Context](https://docs.ollama.com/context-length) - Official context configuration
- [r/LocalLLaMA benchmarks](https://www.reddit.com/r/LocalLLaMA/comments/1plbjqg/) - Community SWE-bench results
- [Devstral HuggingFace](https://huggingface.co/mistralai/Devstral-Small-2-24B-Instruct-2512) - Model card
- [Granite4 InfoQ](https://www.infoq.com/news/2025/11/ibm-granite-mamba2-enterprise/) - Architecture details

### Links

- Release: [v1.4.0](https://github.com/FlorianBruniaux/cc-copilot-bridge/releases/tag/v1.4.0)
- Commits: [v1.3.0...v1.4.0](https://github.com/FlorianBruniaux/cc-copilot-bridge/compare/v1.3.0...v1.4.0)

---

## [1.3.0] - 2026-01-22

### Fixed

**claude-switch v1.3.0 - Prompt Injection Bug**
- ğŸ› Fixed "am" appearing automatically at startup when using `ccc-gpt`
- ğŸ”§ Replaced `eval` string execution with native bash arrays for prompt injection
- âœ… Proper handling of newlines and special characters in system prompts
- ğŸ” Eliminated command injection vulnerability from prompt content
- ğŸ“ Technical details: [BUGFIX-AM.md](BUGFIX-AM.md)

**install.sh**
- ğŸ› Fixed `ccc-gpt` alias pointing to incompatible `gpt-5.2-codex` â†’ changed to `gpt-4.1`

### Added

**Documentation**
- ğŸ“ Documentation complÃ¨te de l'issue copilot-api #174 (Reserved Billing Header Error) dans TROUBLESHOOTING.md
- ğŸ“ Guide dÃ©taillÃ© d'application du patch communautaire (@mrhanhan) pour filtrer `x-anthropic-billing-header`
- ğŸ“ Documentation du script de test automatique dans scripts/README.md

**Scripts**
- âœ¨ Nouveau script `scripts/test-billing-header-fix.sh` pour tester le fix de l'issue #174
  - VÃ©rifie que copilot-api filtre correctement le header rÃ©servÃ©
  - Test automatique avec requÃªtes systÃ¨me simulant Claude Code v2.1.15+
  - Validation complÃ¨te : requÃªte avec billing header + requÃªte normale (contrÃ´le)
- ğŸ“‹ Nouveau `scripts/README.md` documentant tous les scripts utilitaires du projet

**Visual Examples**
- ğŸ“¸ 6 screenshots ajoutÃ©s dans `assets/` pour documentation visuelle
  - Claude Sonnet 4.5 (default model)
  - Claude Opus 4.5 (premium quality)
  - GPT-4.1 (OpenAI)
  - Ollama offline (100% private)
  - Help menu (claude-switch --help)
  - copilot-api proxy server logs
- ğŸ¨ Screenshots intÃ©grÃ©s dans README.md (Usage + Features sections)
- ğŸ¨ Screenshots intÃ©grÃ©s dans QUICKSTART.md (First Use section)

**Documentation Overhaul**
- ğŸ“ **TL;DR technique** ajoutÃ© en haut du README (comprÃ©hension immÃ©diate)
- ğŸ“ **Optimisation positionnement GitHub** : killer metrics en ligne 28 (au lieu de 101)
- ğŸ“ **Positionnement confiant** : "Serving Copilot Pro+ subscribers specifically"
- ğŸ“ Retrait langage dÃ©fensif et marketing excessif
- ğŸ“ Structure claire : Core (Copilot) â†’ Bonus (Ollama) â†’ Fallback (Anthropic)

**Patch Communautaire**
- ğŸ”§ Patch appliquÃ© Ã  copilot-api v0.7.0 pour filtrer `x-anthropic-billing-header`
  - Modifie `dist/main.js` fonction `translateAnthropicMessagesToOpenAI`
  - Ajoute filtrage regex pour supprimer le header rÃ©servÃ© du system prompt
  - Log de confirmation : "Filtered x-anthropic-billing-header from system message"
  - Backup automatique crÃ©Ã© : `dist/main.js.backup`

### Fixed

- âœ… RÃ©solution de l'erreur `invalid_request_body` avec Claude Code v2.1.15+ via copilot-api
- âœ… CompatibilitÃ© restaurÃ©e entre Claude Code CLI et GitHub Copilot proxy

### Changed

**Repository Organization**
- ğŸ—‚ï¸ CrÃ©ation du dossier `claudedocs/` (non versionnÃ©) pour documentation interne
- ğŸ—‚ï¸ Documentation dÃ©placÃ©e dans `docs/` (CHEATSHEET, CODE_OF_CONDUCT, CONTRIBUTING, FEATURES, ROADMAP)
- ğŸ—‚ï¸ VERSION dÃ©placÃ© dans `scripts/`
- ğŸ§¹ Nettoyage : RECAP.md et SUMMARY.txt supprimÃ©s (obsolÃ¨tes)

**TROUBLESHOOTING.md**
- âš ï¸ Ajout section "Reserved Billing Header Error" avec 3 solutions
  - Option 1: Utiliser Anthropic Direct (`ccd`) - RecommandÃ©
  - Option 2: Utiliser Ollama Local (`cco`) - Alternative gratuite
  - Option 3: Attendre fix officiel copilot-api
- ğŸ”§ Ajout section "Patch communautaire" avec guide Ã©tape par Ã©tape
  - Localisation du fichier Ã  patcher
  - CrÃ©ation backup
  - Application du patch
  - Tests de validation
  - ProcÃ©dure de restauration
  - Limitations et suivi de l'issue officielle

### Technical Details

**Patch copilot-api #174**
- Fichier modifiÃ© : `~/.nvm/versions/node/v22.18.0/lib/node_modules/copilot-api/dist/main.js`
- Fonction patchÃ©e : `translateAnthropicMessagesToOpenAI` (ligne 897)
- Regex utilisÃ©e : `/x-anthropic-billing-header: \?cc_version=.+; \?cc_entrypoint=\\+\n{0,2}\./`
- Impact : Filtre automatique du header rÃ©servÃ© avant envoi Ã  l'API Anthropic
- CompatibilitÃ© : TestÃ© avec copilot-api v0.7.0, Claude Code v2.1.15

**Script de test**
- Langage : Bash
- DÃ©pendances : `curl`, `nc`, `jq`
- Tests : 2 requÃªtes POST /v1/messages (avec/sans billing header)
- Exit code : 0 si succÃ¨s, 1 si Ã©chec
- Logs : Console + vÃ©rification logs copilot-api

### Links

- Issue GitHub : [copilot-api#174](https://github.com/ericc-ch/copilot-api/issues/174)
- Patch original : [@mrhanhan comment](https://github.com/ericc-ch/copilot-api/issues/174#issuecomment)
- Documentation : [TROUBLESHOOTING.md - Patch communautaire](docs/TROUBLESHOOTING.md#patch-communautaire-solution-avancÃ©e)
- Release : [v1.3.0](https://github.com/FlorianBruniaux/cc-copilot-bridge/releases/tag/v1.3.0)
- Commits : [v1.2.0...v1.3.0](https://github.com/FlorianBruniaux/cc-copilot-bridge/compare/v1.2.0...v1.3.0)

---

## [1.2.0] - 2026-01-21

### Added

**MCP Profiles System**
- âœ¨ Auto-generated MCP profiles for strict model validation (GPT-4.1)
- âœ¨ Model identity injection via system prompts
- âœ¨ Dynamic profile selection based on model type

**Documentation**
- ğŸ“ MCP-PROFILES.md guide
- ğŸ“ MODEL-SWITCHING.md comprehensive guide

---

## [1.0.0] - 2026-01-20

### Added

**Core Features**
- âœ¨ Multi-provider support: Anthropic Direct, GitHub Copilot, Ollama
- âœ¨ Dynamic model switching via `COPILOT_MODEL` environment variable
- âœ¨ Health checks before provider switching (port availability, model existence)
- âœ¨ Comprehensive session logging (timestamps, durations, exit codes, models used)
- âœ¨ Smart shell aliases for instant switching
- âœ¨ Status command to check all providers at once

**Providers**
- ğŸš€ **Anthropic Direct**: Official API, best quality, production-ready
- ğŸ’° **GitHub Copilot**: Free with Copilot Pro+ subscription (via copilot-api proxy)
- ğŸ”’ **Ollama Local**: 100% private, offline capable, local inference

**Shell Aliases**
- `ccd` â†’ Anthropic Direct
- `ccc` â†’ GitHub Copilot (default: Sonnet 4.5)
- `cco` â†’ Ollama Local
- `ccs` â†’ Status check all providers
- `ccc-opus` â†’ Copilot with Claude Opus 4.5
- `ccc-sonnet` â†’ Copilot with Claude Sonnet 4.5
- `ccc-haiku` â†’ Copilot with Claude Haiku 4.5
- `ccc-gpt` â†’ Copilot with GPT-5.2 Codex

**Supported Models** (via GitHub Copilot)
- **Claude**: Opus 4.5, Sonnet 4.5, Sonnet 4, Opus 41, Haiku 4.5
- **GPT**: 5.2 Codex, 5.2, 5.1 Codex, 5.1 Codex Max, 5 Mini, 4o variants
- **Gemini**: 3 Pro Preview, 3 Flash Preview, 2.5 Pro
- **Grok**: Code Fast 1
- **Embedding**: text-embedding-3-small

**Documentation**
- ğŸ“š Comprehensive README with examples and troubleshooting
- ğŸ“– MODEL-SWITCHING.md guide for dynamic model selection
- ğŸ—ï¸ REPO-STRUCTURE.md for repo organization
- âš™ï¸ Automatic installation script with OS detection

**Logging Features**
- Session start/end timestamps
- Provider and model used
- Working directory path
- Process ID tracking
- Duration calculation (minutes/seconds)
- Exit code tracking
- Colored console output (errors, warnings, info)

### Technical Details

**Script Features**
- Bash 4+ compatible
- Error handling with `set -euo pipefail`
- Health check functions with timeouts
- Session tracking with environment variables
- Colored output for better UX
- Modular function design
- Fail-fast on missing dependencies

**Environment Variables Set**
- `ANTHROPIC_BASE_URL` (provider-specific)
- `ANTHROPIC_AUTH_TOKEN` (provider-specific)
- `ANTHROPIC_MODEL` (dynamic model selection)
- `ANTHROPIC_API_KEY` (Ollama)
- `DISABLE_NON_ESSENTIAL_MODEL_CALLS` (Copilot)
- `CLAUDE_CODE_DISABLE_NONESSENTIAL_TRAFFIC` (Copilot)
- `COPILOT_MODEL` (user-controlled model override)

**Tested Platforms**
- âœ… macOS (M4 Pro, 48GB RAM)
- âœ… Linux (Ubuntu/Debian)
- âŒ Windows (not supported yet)

### Performance

**Latency Benchmarks** (tested on MacBook Pro M4 Pro)
- Anthropic Direct: ~1-2s first token
- GitHub Copilot: ~1-2s first token
- Ollama 32b: ~5-10s first token (local)
- Ollama 7b: ~2-3s first token (local)

**Resource Usage**
- Script overhead: <5MB RAM
- Log file: ~1KB per session
- No background processes

### Security & Privacy

**Data Flow**
- Anthropic Direct: Data sent to Anthropic cloud
- GitHub Copilot: Data sent through Copilot API (Microsoft/GitHub)
- Ollama: 100% local, no external data transmission

**Logging Privacy**
- Log file location: `~/.claude/claude-switch.log`
- Contains: timestamps, providers, durations, working directories
- Does NOT contain: code content, API keys, personal data
- Recommended: Add to `.gitignore`

### Known Limitations

- No Windows support (Bash script)
- Requires netcat (nc) for health checks
- copilot-api must be manually started/managed
- Ollama requires manual model pulling
- No automatic provider fallback on failure
- No cost tracking

### Breaking Changes

None (initial release)

### Deprecated

None (initial release)

### Removed

None (initial release)

### Fixed

None (initial release)

### Security

- No known security vulnerabilities
- Script does not handle API keys directly
- Relies on existing environment variables
- Log file contains only metadata

---

## [Unreleased]

### Planned for v1.1

- [ ] Windows PowerShell support
- [ ] Shell completion (Bash/Zsh)
- [ ] Automated tests (health checks, model switching)
- [ ] Better error messages for common issues
- [ ] Config file support (`~/.claude-switch.conf`)

### Planned for v1.2

- [ ] Web UI for status monitoring
- [ ] Cost tracking per provider
- [ ] Usage analytics and reports
- [ ] Automatic provider selection based on context
- [ ] Background service mode for copilot-api

### Planned for v2.0

- [ ] Plugin system for custom providers
- [ ] OpenRouter integration
- [ ] Perplexity integration
- [ ] Team configuration sync
- [ ] Session replay from logs

---

## Contributing

See [REPO-STRUCTURE.md](REPO-STRUCTURE.md) for contribution guidelines.

---

## Links

- **Repository**: https://github.com/FlorianBruniaux/cc-copilot-bridge
- **Issues**: https://github.com/FlorianBruniaux/cc-copilot-bridge/issues

[1.5.0]: https://github.com/FlorianBruniaux/cc-copilot-bridge/releases/tag/v1.5.0
[1.4.0]: https://github.com/FlorianBruniaux/cc-copilot-bridge/releases/tag/v1.4.0
[1.3.0]: https://github.com/FlorianBruniaux/cc-copilot-bridge/releases/tag/v1.3.0
[1.2.0]: https://github.com/FlorianBruniaux/cc-copilot-bridge/releases/tag/v1.2.0
[1.0.0]: https://github.com/FlorianBruniaux/cc-copilot-bridge/releases/tag/v1.0.0
[Unreleased]: https://github.com/FlorianBruniaux/cc-copilot-bridge/compare/v1.5.0...HEAD
